{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempts to intergrate Grover's Algorithm into the Top-K Scoring System for Quadratic Speedup of Large Language Models.\n",
    "This is a primitive experiment as aforementioned in the README.md to use Grover's Algorithm for Vector Similarity Search. These series of experiments \n",
    "attempt to speed up Gaia's Vector Search process. Though these were mostly for fun, prototype versions of using Grover's Algorithm with Top-K scoring did make it into the first versions of Gaia though as of v1.0.4 for the sake of an decently operational demo to forgo the custom Top-K scoring system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grover's Algorithm Case Study with GreenQuest\n",
    "\n",
    "Grover's algorithm allows us to find a particular register or in this case vector in an unordered database with $N$ entries in just $O(\\sqrt{N})$ steps, compared to the best classical algorithm taking on average $N/2$ steps, thereby providing a __quadratic speedup__.\n",
    "\n",
    "For large databases (with a large number of entries, $N$), a quadratic speedup can provide a significant advantage. For a database with one million entries, a quantum computer running Grover's algorithm would need about 1000 runs, while a classical computer would need, on average, $500$k runs.\n",
    "\n",
    "Research has been shown that any optimal quantum solution to an unstructured search problem has a speed limit of $O(\\sqrt{N})$ runtime. This research finding matches the performance of Grover's algorithm, thus proving that the algorithm is asymptotically optimal. In fact, Grover's algorithm can be generalized to accelerate any type of search where one can construct a quantum oracle. \n",
    "\n",
    "In the context of GreenQuest's top-k scoring method, Grover's algorithm could be used to significantly improve the efficiency of searching and ranking user activities based on sustainability impact. With a vast database of user actions and their sustainability scores, Grover's algorithm could quickly identify the top-scoring actions. This efficiency is crucial for real-time applications where immediate access to the most impactful sustainability actions is necessary. Integrating Grover's algorithm into GreenQuest could theorectically enhance the platform's capability to offer quicker, more efficient services, thus fostering greater user engagement and promoting effective sustainability practices. While this Quantum Scoring System was never used in the demo version, I thought it would be cool to share it in this notebook the testing methods of what could've been. \n",
    "\n",
    "This notebook is a primitive test case to use for replication and shouldn't be considered production grade code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replication \n",
    "To replicate, we must first install Qiskit (Tests were done on Quantum Hardware (IOQ) ). Bless the people at AWS who let Free Tier members have 1 Hour of Free Circuit Simulator Time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: torchsde 0.2.5 has a non-standard dependency specifier numpy>=1.19.*; python_version >= \"3.7\". pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of torchsde or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting qiskit\n",
      "  Downloading qiskit-0.45.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.24.3)\n",
      "Collecting qiskit-terra==0.45.1 (from qiskit)\n",
      "  Downloading qiskit_terra-0.45.1-cp38-abi3-win_amd64.whl.metadata (12 kB)\n",
      "Collecting rustworkx>=0.13.0 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading rustworkx-0.13.2-cp311-cp311-win_amd64.whl.metadata (10 kB)\n",
      "Collecting ply>=3.10 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
      "     ---------------------------------------- 0.0/49.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 49.6/49.6 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: psutil>=5 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from qiskit-terra==0.45.1->qiskit) (5.9.5)\n",
      "Requirement already satisfied: scipy>=1.5 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from qiskit-terra==0.45.1->qiskit) (1.11.2)\n",
      "Requirement already satisfied: sympy>=1.3 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from qiskit-terra==0.45.1->qiskit) (1.12)\n",
      "Collecting dill>=0.3 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from qiskit-terra==0.45.1->qiskit) (2.8.2)\n",
      "Collecting stevedore>=3.0.0 (from qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading stevedore-5.1.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from python-dateutil>=2.8.0->qiskit-terra==0.45.1->qiskit) (1.16.0)\n",
      "Collecting pbr!=2.1.0,>=2.0.0 (from stevedore>=3.0.0->qiskit-terra==0.45.1->qiskit)\n",
      "  Downloading pbr-6.0.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ty chermsirivatana\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy>=1.3->qiskit-terra==0.45.1->qiskit) (1.3.0)\n",
      "Downloading qiskit-0.45.1-py3-none-any.whl (9.6 kB)\n",
      "Downloading qiskit_terra-0.45.1-cp38-abi3-win_amd64.whl (5.1 MB)\n",
      "   ---------------------------------------- 0.0/5.1 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.3/5.1 MB 7.0 MB/s eta 0:00:01\n",
      "   ------ --------------------------------- 0.9/5.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 1.6/5.1 MB 11.2 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.6/5.1 MB 14.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 4.0/5.1 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  5.1/5.1 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.1/5.1 MB 18.3 MB/s eta 0:00:00\n",
      "Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
      "   ---------------------------------------- 0.0/115.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 115.3/115.3 kB 7.0 MB/s eta 0:00:00\n",
      "Downloading rustworkx-0.13.2-cp311-cp311-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 45.7 MB/s eta 0:00:00\n",
      "Downloading stevedore-5.1.0-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.6/49.6 kB ? eta 0:00:00\n",
      "Downloading pbr-6.0.0-py2.py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.5/107.5 kB 6.5 MB/s eta 0:00:00\n",
      "Installing collected packages: ply, rustworkx, pbr, dill, stevedore, qiskit-terra, qiskit\n",
      "Successfully installed dill-0.3.7 pbr-6.0.0 ply-3.11 qiskit-0.45.1 qiskit-terra-0.45.1 rustworkx-0.13.2 stevedore-5.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install qiskit qiskit-aer scikit-learn numpy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all neccessary libraries as such. This imports qiskit, numpy and sk-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import Aer, transpile, assemble\n",
    "from qiskit.algorithms import AmplificationProblem, Grover\n",
    "from qiskit.circuit.library import Diagonal\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, these functions below just convert Text to Vector Embeddings, Prepare the Quantum Oracle for Grover's Algorithm for Top K and Constructs the QC Circut for Simulation. In addition, it also adjusts vectors to prevent CircuitErrors if the number of Vectors aren't a power of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Convert Text to Vector Embeddings\n",
    "def convert_texts_to_vectors(texts):\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    X = vectorizer.fit_transform(texts)\n",
    "    return X.toarray()\n",
    "\n",
    "\n",
    "# Step 2: Prepare Oracle for Grover's Algorithm for Top-K Scoring\n",
    "def prepare_oracle_top_k(query_vector, vectors, k):\n",
    "    similarities = np.dot(vectors, query_vector)\n",
    "    top_k_indices = np.argsort(similarities)[-k:]\n",
    "    diag_elements = np.ones(len(vectors))\n",
    "    diag_elements[top_k_indices] = -1\n",
    "    oracle = Diagonal(diag_elements)\n",
    "    return oracle, top_k_indices, similarities\n",
    "\n",
    "#Step 3: Run Grover's Algorithm for Top-K Scoring. This does use some timing functions so it isn't as efficent.\n",
    "def run_grovers_algorithm_top_k(query_vector, vectors, texts, k):\n",
    "    top_k_results = []\n",
    "    for _ in range(k):\n",
    "        start_time = time.time()\n",
    "        oracle, potential_top_k_indices, similarities = prepare_oracle_top_k(query_vector, vectors, k)\n",
    "        problem = AmplificationProblem(oracle, is_good_state=lambda x: x in potential_top_k_indices)\n",
    "        grover = Grover()\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "        qc = grover.construct_circuit(problem, power=1)\n",
    "        qc.measure_all()\n",
    "        tqc = transpile(qc, backend)\n",
    "        qobj = assemble(tqc)\n",
    "        result = backend.run(qobj).result()\n",
    "        measurements = result.get_counts(qc)\n",
    "        most_frequent = max(measurements, key=measurements.get)\n",
    "        found_index = int(most_frequent, 2)\n",
    "        end_time = time.time()\n",
    "        # Store results including the text and similarity score\n",
    "        result_info = {\n",
    "            'index': found_index,\n",
    "            'vector': vectors[found_index] if found_index < len(vectors) else None,\n",
    "            'text': texts[found_index] if found_index < len(texts) else None,\n",
    "            'score': similarities[found_index],\n",
    "            'time': end_time - start_time\n",
    "        }\n",
    "        top_k_results.append(result_info)\n",
    "\n",
    "    return top_k_results\n",
    "\n",
    "# Function to adjust the number of vectors to a power of 2\n",
    "def adjust_vectors_to_power_of_2(vectors):\n",
    "    next_power_of_2 = 2 ** np.ceil(np.log2(len(vectors)))\n",
    "    padding_length = int(next_power_of_2 - len(vectors))\n",
    "    if padding_length > 0:\n",
    "        padding = np.zeros((padding_length, vectors.shape[1]))\n",
    "        vectors = np.vstack([vectors, padding])\n",
    "    return vectors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've went ahead here and sent up some fake GreenQuest strings just to simulate real life queries. You can add as many as you realistically want. To do comparision, the first string of the list will be the test string to compare to other strings.\n",
    "\n",
    "I would like to also forewarn people who are running this code that you may get a circuit error depending on the number of vectors. Just ensure that the number of vectors is a power of 2. I've included a function to help default that, just something to note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "greenquest_text_strings = [\n",
    "    \"Tell me about the Center for Sustainability Education (CSE) and its objectives.\",  # Query vector\n",
    "    \"The CSE at Dickinson focuses on integrating sustainability into the college's liberal arts curriculum and promoting civic action among students.\",\n",
    "    \"Sustainability and social justice are key components of Dickinson's educational approach, as guided by the Center for Sustainability Education.\",\n",
    "    \"Dickinson College's CSE has been instrumental in advancing sustainability and environmental awareness in higher education.\",\n",
    "    \"How does the CSE's strategic plan address challenges like reduced staffing and financial resources while maintaining its sustainability goals?\",\n",
    "    \"The Center for Sustainability Education emphasizes the importance of global interdependence and equity in its sustainability teachings.\",\n",
    "    \"CSE's efforts to make antiracism and social justice central to sustainability practices reflect Dickinson College's commitment to inclusivity.\",\n",
    "    \"What new goals has the Center for Sustainability Education set for the 2021-2026 period to enhance its educational and civic impact?\",\n",
    "    \"Dickinson's CSE offers students opportunities to develop sustainability skills through various co-curricular programs and off-campus studies.\",\n",
    "    \"As a leader in sustainability education, how does the Center for Sustainability Education at Dickinson attract and retain high-quality faculty and staff?\",\n",
    "    # False strings\n",
    "    \"Dickinson College has launched a space program to study the sustainability of life on Mars.\",\n",
    "    \"The college's new mascot, a giant walking tree, symbolizes its focus on deep forest ecology.\",\n",
    "    \"Dickinson's CSE has developed a groundbreaking technology to turn textbooks into renewable energy.\",\n",
    "    \"The college plans to relocate to a fully underwater campus to promote marine biology studies.\",\n",
    "    \"A recent study at Dickinson claims that listening to classical music increases plant growth.\",\n",
    "    \"Dickinson College is famous for its annual underwater basket weaving competition.\",\n",
    "    \"The CSE has introduced a program for training squirrels to assist in campus tree planting efforts.\"\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, this is the fun part. I've defined the code below to define the Top Vectors. The code below should vectorize everything and run Grover's algorithm for Top-K for scoring. Essentially, primitive Quantum Vector Searching using Top-K scoring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ty Chermsirivatana\\AppData\\Local\\Temp\\ipykernel_1152\\3333038729.py:38: DeprecationWarning: Using a qobj for run() is deprecated as of qiskit-aer 0.9.0 and will be removed no sooner than 3 months from that release date. Transpiled circuits should now be passed directly using `backend.run(circuits, **run_options).\n",
      "  result = backend.run(qobj).result()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 5\n",
      "Text: The Center for Sustainability Education emphasizes the importance of global interdependence and equity in its sustainability teachings.\n",
      "Vector: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.14490597 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20375628\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.18878964 0.         0.         0.31042159 0.\n",
      " 0.         0.         0.31042159 0.         0.         0.\n",
      " 0.         0.         0.17582495 0.         0.         0.\n",
      " 0.31042159 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.31042159 0.22145805\n",
      " 0.         0.         0.         0.         0.31042159 0.\n",
      " 0.         0.         0.18878964 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.24312327 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.2729159  0.         0.31042159 0.         0.         0.\n",
      " 0.         0.2729159  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Similarity Score: 1.0000\n",
      "Time taken: 0.0250 seconds\n",
      "\n",
      "Index: 12\n",
      "Text: Dickinson's CSE has developed a groundbreaking technology to turn textbooks into renewable energy.\n",
      "Vector: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.17679705 0.\n",
      " 0.         0.         0.         0.33385159 0.15584318 0.\n",
      " 0.         0.         0.         0.         0.         0.33385159\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.33385159 0.         0.         0.21913539\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.29151326\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.33385159 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.33385159 0.         0.33385159\n",
      " 0.         0.         0.         0.17679705 0.         0.\n",
      " 0.33385159 0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Similarity Score: 1.0000\n",
      "Time taken: 0.0323 seconds\n",
      "\n",
      "Index: 16\n",
      "Text: The CSE has introduced a program for training squirrels to assist in campus tree planting efforts.\n",
      "Vector: [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.31757259 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.24872396 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.16817622 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.27729872 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.17987532 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.20845009\n",
      " 0.         0.         0.         0.         0.         0.22655965\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.31757259 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31757259\n",
      " 0.         0.27729872 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.31757259\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.13960145 0.         0.16817622 0.31757259 0.27729872\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n",
      "Similarity Score: 1.0000\n",
      "Time taken: 0.0330 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert texts to vector embeddings and adjust to power of 2\n",
    "vectors = convert_texts_to_vectors(greenquest_text_strings)\n",
    "vectors = adjust_vectors_to_power_of_2(vectors)\n",
    "\n",
    "# Choose a query vector (This uses the first vector in the list)\n",
    "query_vector = vectors[0]\n",
    "\n",
    "# Define the number of top vectors to find (K)\n",
    "K = 3\n",
    "\n",
    "# Calculate similarity scores for all vectors using Grover's Algorithm\n",
    "all_results = []\n",
    "for i in range(1, len(vectors)):\n",
    "    result = run_grovers_algorithm_top_k(vectors[i], vectors, greenquest_text_strings, 1)\n",
    "    all_results.append(result[0])  # Append the first result from the Grover's Algorithm run\n",
    "\n",
    "# Sort all results by similarity score in descending order\n",
    "sorted_all_results = sorted(all_results, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "# Select the top 3 results\n",
    "top_3_results = sorted_all_results[:3]\n",
    "\n",
    "# Output the top 3 sorted results\n",
    "for result in top_3_results:\n",
    "    print(f\"Index: {result['index']}\")\n",
    "    print(f\"Text: {result['text']}\")\n",
    "    print(f\"Vector: {result['vector']}\")\n",
    "    print(f\"Similarity Score: {result['score']:.4f}\")\n",
    "    print(f\"Time taken: {result['time']:.4f} seconds\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "Overall, these experiments did produce some interesting finds, I'm still seeing some perfect similarity scores which is interesting. Either my Top-K implementation isn't working or there's something wrong with the similarity scoring? I may want to consult someone more proficent than me. Maybe it's a issue with Vectorization or Implementation of Grover's? One note is that I'm not a expert, just a simple amateur freshman not even aiming for Computer Science. If there is anything irregular or weird in this findings that could help improve my comptency, please write me at chermsit@dickinson.edu or drop a Github Issue!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
